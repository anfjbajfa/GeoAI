{
          "cells": [
                    {
                              "cell_type": "code",
                              "execution_count": 5,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import numpy as np\n",
                                        "import os\n",
                                        "\n",
                                        "from osgeo import gdal\n",
                                        "# os.environ['PROJ_LIB'] = r'C:\\Users\\Lenovo\\.conda\\envs\\zph\\Library\\share\\proj'\n",
                                        "# os.environ['GDAL_DATA'] = r'C:\\Users\\Lenovo\\.conda\\envs\\zph\\Library\\share'\n",
                                        "# gdal.PushErrorHandler(\"CPLQuietErrorHandler\")\n",
                                        "\n",
                                        "class ImageProcess:\n",
                                        "    def __init__(self, filepath: str):\n",
                                        "        self.filepath = filepath\n",
                                        "        self.dataset = gdal.Open(self.filepath, gdal.GA_ReadOnly)\n",
                                        "        self.info = []\n",
                                        "        self.img_data = None\n",
                                        "        self.data_8bit = None\n",
                                        "\n",
                                        "    def read_img_info(self):\n",
                                        "        # 获取波段、宽、高\n",
                                        "        img_bands = self.dataset.RasterCount\n",
                                        "        img_width = self.dataset.RasterXSize\n",
                                        "        img_height = self.dataset.RasterYSize\n",
                                        "        # 获取仿射矩阵、投影\n",
                                        "        img_geotrans = self.dataset.GetGeoTransform()\n",
                                        "        img_proj = self.dataset.GetProjection()\n",
                                        "        self.info = [img_bands, img_width, img_height, img_geotrans, img_proj]\n",
                                        "        return self.info\n",
                                        "\n",
                                        "    def read_img_data(self):\n",
                                        "        self.img_data = self.dataset.ReadAsArray(0, 0, self.info[1], self.info[2])\n",
                                        "        return self.img_data\n",
                                        "\n",
                                        "    # 影像写入文件\n",
                                        "    @staticmethod\n",
                                        "    def write_img(filename: str, img_data: np.array, **kwargs):\n",
                                        "        # 判断栅格数据的数据类型\n",
                                        "        if 'int8' in img_data.dtype.name:\n",
                                        "            datatype = gdal.GDT_Byte\n",
                                        "        elif 'int16' in img_data.dtype.name:\n",
                                        "            datatype = gdal.GDT_UInt16\n",
                                        "        else:\n",
                                        "            datatype = gdal.GDT_Float32\n",
                                        "        # 判读数组维数\n",
                                        "        if len(img_data.shape) >= 3:\n",
                                        "            img_bands, img_height, img_width = img_data.shape\n",
                                        "        else:\n",
                                        "            img_bands, (img_height, img_width) = 1, img_data.shape\n",
                                        "        # 创建文件\n",
                                        "        driver = gdal.GetDriverByName(\"GTiff\")\n",
                                        "        outdataset = driver.Create(filename, img_width, img_height, img_bands, datatype)\n",
                                        "        # 写入仿射变换参数\n",
                                        "        if 'img_geotrans' in kwargs:\n",
                                        "            outdataset.SetGeoTransform(kwargs['img_geotrans'])\n",
                                        "        # 写入投影\n",
                                        "        if 'img_proj' in kwargs:\n",
                                        "            outdataset.SetProjection(kwargs['img_proj'])\n",
                                        "        # 写入文件\n",
                                        "        if img_bands == 1:\n",
                                        "            outdataset.GetRasterBand(1).WriteArray(img_data)  # 写入数组数据\n",
                                        "        else:\n",
                                        "            for i in range(img_bands):\n",
                                        "                outdataset.GetRasterBand(i + 1).WriteArray(img_data[i])\n",
                                        "\n",
                                        "        del outdataset\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 6,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "def read_multi_bands(image_path):\n",
                                        "    \"\"\"\n",
                                        "    读取多波段文件\n",
                                        "    :param image_path: 多波段文件路径\n",
                                        "    :return: 影像对象，影像元信息，影像矩阵\n",
                                        "    \"\"\"\n",
                                        "    # 影像读取\n",
                                        "    image = ImageProcess(filepath=image_path)\n",
                                        "    # 读取影像元信息\n",
                                        "    image_info = image.read_img_info()\n",
                                        "    print(f\"多波段影像元信息：{image_info}\")\n",
                                        "    # 读取影像矩阵\n",
                                        "    image_data = image.read_img_data()\n",
                                        "    print(f\"多波段矩阵大小：{image_data.shape}\")\n",
                                        "    return image, image_info, image_data\n",
                                        "\n",
                                        "\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 11,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 单波段的images\n",
                                        "def read_single_band(band_path):\n",
                                        "    \"\"\"\n",
                                        "    读取单波段文件\n",
                                        "    :param band_path: 单波段文件路径\n",
                                        "    :return: 影像对象，影像元信息，影像矩阵\n",
                                        "    \"\"\"\n",
                                        "    # 影像读取\n",
                                        "    band = ImageProcess(filepath=band_path)\n",
                                        "    # 读取影像元信息\n",
                                        "    band_info = band.read_img_info()\n",
                                        "    print(f\"单波段影像元信息：{band_info}\")\n",
                                        "    # 读取影像矩阵\n",
                                        "    band_data = band.read_img_data()\n",
                                        "    print(f\"单波段矩阵大小：{band_data.shape}\")\n",
                                        "    return band, band_info, band_data\n",
                                        "\n",
                                        "\n",
                                        "import math\n",
                                        "import numpy as np\n",
                                        "from alive_progress import alive_bar\n",
                                        "# from module.image import *\n",
                                        "\n",
                                        "\n",
                                        "def cal_single_band_slice(single_band_data, slice_size=512):\n",
                                        "    \"\"\"\n",
                                        "    计算单波段的格网裁剪四角点\n",
                                        "    :param single_band_data:单波段原始数据\n",
                                        "    :param slice_size: 裁剪大小\n",
                                        "    :return: 嵌套列表，每一个块的四角行列号\n",
                                        "    \"\"\"\n",
                                        "    single_band_size = single_band_data.shape\n",
                                        "    row_num = math.ceil(single_band_size[0] / slice_size)  # 向上取整\n",
                                        "    col_num = math.ceil(single_band_size[1] / slice_size)  # 向上取整\n",
                                        "    print(f\"行列数：{single_band_size}，行分割数量：{row_num}，列分割数量：{col_num}\")\n",
                                        "    slice_index = []\n",
                                        "    for i in range(row_num):\n",
                                        "        for j in range(col_num):\n",
                                        "            row_min = i * slice_size\n",
                                        "            row_max = (i + 1) * slice_size\n",
                                        "            if (i + 1) * slice_size > single_band_size[0]:\n",
                                        "                row_max = single_band_size[0]\n",
                                        "            col_min = j * slice_size\n",
                                        "            col_max = (j + 1) * slice_size\n",
                                        "            if (j + 1) * slice_size > single_band_size[1]:\n",
                                        "                col_max = single_band_size[1]\n",
                                        "            slice_index.append([row_min, row_max, col_min, col_max])\n",
                                        "    return slice_index\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "def single_band_slice(single_band_data, index=[0, 1000, 0, 1000], slice_size=1000, edge_fill=False):\n",
                                        "    \"\"\"\n",
                                        "    依据四角坐标，切分单波段影像\n",
                                        "    :param single_band_data:原始矩阵数据\n",
                                        "    :param index: 四角坐标\n",
                                        "    :param slice_size: 分块大小\n",
                                        "    :param edge_fill: 是否进行边缘填充\n",
                                        "    :return: 切分好的单波段矩阵\n",
                                        "    \"\"\"\n",
                                        "    if edge_fill:\n",
                                        "        if (index[1] - index[0] != slice_size) or (index[3] - index[2] != slice_size):\n",
                                        "            result = np.empty(shape=(slice_size, slice_size))\n",
                                        "            new_row_min = index[0] % slice_size\n",
                                        "            new_row_max = new_row_min + (index[1] - index[0])\n",
                                        "            new_col_min = index[2] % slice_size\n",
                                        "            new_col_max = new_col_min + (index[3] - index[2])\n",
                                        "            result[new_row_min:new_row_max, new_col_min:new_col_max] = single_band_data[index[0]:index[1],\n",
                                        "                                                                       index[2]:index[3]]\n",
                                        "        else:\n",
                                        "            result = single_band_data[index[0]:index[1], index[2]:index[3]]\n",
                                        "    else:\n",
                                        "        result = single_band_data[index[0]:index[1], index[2]:index[3]]\n",
                                        "    return result.astype(single_band_data.dtype)\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "def slice_conbine(slice_all, slice_index):\n",
                                        "    \"\"\"\n",
                                        "    将分块矩阵进行合并\n",
                                        "    :param slice_all: 所有的分块矩阵列表\n",
                                        "    :param slice_index: 分块的四角坐标\n",
                                        "    :return: 合并的矩阵\n",
                                        "    \"\"\"\n",
                                        "    combine_data = np.zeros(shape=(slice_index[-1][1], slice_index[-1][3]))\n",
                                        "    # print(combine_data.shape)\n",
                                        "    for i, slice_element in enumerate(slice_index):\n",
                                        "        combine_data[slice_element[0]:slice_element[1], slice_element[2]:slice_element[3]] = slice_all[i]\n",
                                        "    return combine_data\n",
                                        "\n",
                                        "\n",
                                        "def coordtransf(Xpixel, Ypixel, GeoTransform):\n",
                                        "    \"\"\"\n",
                                        "    像素坐标和地理坐标仿射变换\n",
                                        "    :param Xpixel: 左上角行号\n",
                                        "    :param Ypixel: 左上角列号\n",
                                        "    :param GeoTransform: 原始仿射矩阵\n",
                                        "    :return: 新的仿射矩阵\n",
                                        "    \"\"\"\n",
                                        "    XGeo = GeoTransform[0] + GeoTransform[1] * Xpixel + Ypixel * GeoTransform[2]\n",
                                        "    YGeo = GeoTransform[3] + GeoTransform[4] * Xpixel + Ypixel * GeoTransform[5]\n",
                                        "    slice_geotrans = (XGeo, GeoTransform[1], GeoTransform[2], YGeo, GeoTransform[4], GeoTransform[5])\n",
                                        "    return slice_geotrans\n",
                                        "\n",
                                        "\n",
                                        "def single_band_grid_slice(band_path, band_slice_dir, slice_size, edge_fill=False):\n",
                                        "    \"\"\"\n",
                                        "    单波段格网裁剪\n",
                                        "    :param band_path: 原始单波段影像\n",
                                        "    :param band_slice_dir: 裁剪保存文件夹\n",
                                        "    :param slice_size: 裁剪大小\n",
                                        "    :return:\n",
                                        "    \"\"\"\n",
                                        "    band, band_info, band_data = read_single_band(band_path)\n",
                                        "    # 计算分块的四角行列号\n",
                                        "    slice_index = cal_single_band_slice(band_data, slice_size=slice_size)\n",
                                        "    # 执行裁剪\n",
                                        "    with alive_bar(len(slice_index), force_tty=True) as bar:\n",
                                        "        for i, slice_element in enumerate(slice_index):\n",
                                        "            slice_data = single_band_slice(band_data, index=slice_element, slice_size=slice_size,\n",
                                        "                                           edge_fill=edge_fill)  # 裁剪单波段影像\n",
                                        "            slice_geotrans = coordtransf(slice_element[2], slice_element[0], band_info[3])  # 转换仿射坐标\n",
                                        "            band.write_img(band_slice_dir + r'\\single_grid_slice_' + str(i) + '.tif', slice_data,\n",
                                        "                           img_geotrans=slice_geotrans, img_proj=band_info[4])  # 写入文件\n",
                                        "            bar()\n",
                                        "        print('单波段格网裁剪完成')"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 12,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 多波段的images\n",
                                        "def read_multi_bands(image_path):\n",
                                        "    \"\"\"\n",
                                        "    读取多波段文件\n",
                                        "    :param image_path: 多波段文件路径\n",
                                        "    :return: 影像对象，影像元信息，影像矩阵\n",
                                        "    \"\"\"\n",
                                        "    # 影像读取\n",
                                        "    image = ImageProcess(filepath=image_path)\n",
                                        "    # 读取影像元信息\n",
                                        "    image_info = image.read_img_info()\n",
                                        "    print(f\"多波段影像元信息：{image_info}\")\n",
                                        "    # 读取影像矩阵\n",
                                        "    image_data = image.read_img_data()\n",
                                        "    print(f\"多波段矩阵大小：{image_data.shape}\")\n",
                                        "    return image, image_info, image_data\n",
                                        "\n",
                                        "\n",
                                        "import math\n",
                                        "import numpy as np\n",
                                        "from alive_progress import alive_bar\n",
                                        "\n",
                                        "def cal_single_band_slice(single_band_data, slice_size=512):\n",
                                        "    \"\"\"\n",
                                        "    计算单波段的格网裁剪四角点\n",
                                        "    :param single_band_data:单波段原始数据\n",
                                        "    :param slice_size: 裁剪大小\n",
                                        "    :return: 嵌套列表，每一个块的四角行列号\n",
                                        "    \"\"\"\n",
                                        "    single_band_size = single_band_data.shape\n",
                                        "    row_num = math.ceil(single_band_size[0] / slice_size)  # 向上取整\n",
                                        "    col_num = math.ceil(single_band_size[1] / slice_size)  # 向上取整\n",
                                        "    print(f\"行列数：{single_band_size}，行分割数量：{row_num}，列分割数量：{col_num}\")\n",
                                        "    slice_index = []\n",
                                        "    for i in range(row_num):\n",
                                        "        for j in range(col_num):\n",
                                        "            row_min = i * slice_size\n",
                                        "            row_max = (i + 1) * slice_size\n",
                                        "            if (i + 1) * slice_size > single_band_size[0]:\n",
                                        "                row_max = single_band_size[0]\n",
                                        "            col_min = j * slice_size\n",
                                        "            col_max = (j + 1) * slice_size\n",
                                        "            if (j + 1) * slice_size > single_band_size[1]:\n",
                                        "                col_max = single_band_size[1]\n",
                                        "            slice_index.append([row_min, row_max, col_min, col_max])\n",
                                        "    return slice_index\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "def multi_bands_slice(multi_bands_data, index=[0, 512, 0, 512], slice_size=512, edge_fill=False):\n",
                                        "    \"\"\"\n",
                                        "    依据四角坐标，切分多波段影像\n",
                                        "    :param multi_bands_data: 原始多波段矩阵\n",
                                        "    :param index: 四角坐标\n",
                                        "    :param slice_size: 分块大小\n",
                                        "    :param edge_fill: 是否进行边缘填充\n",
                                        "    :return: 切分好的多波段矩阵\n",
                                        "    \"\"\"\n",
                                        "    if edge_fill==True:\n",
                                        "        if (index[1] - index[0] != slice_size) or (index[3] - index[2] != slice_size):\n",
                                        "            result = np.empty(shape=(multi_bands_data.shape[0], slice_size, slice_size))\n",
                                        "            new_row_min = index[0] % slice_size    # 0\n",
                                        "            new_row_max = new_row_min + (index[1] - index[0])  \n",
                                        "            new_col_min = index[2] % slice_size    # 0\n",
                                        "            new_col_max = new_col_min + (index[3] - index[2])\n",
                                        "            result[:, new_row_min:new_row_max, new_col_min:new_col_max] = multi_bands_data[:, index[0]:index[1],\n",
                                        "                                                                          index[2]:index[3]]\n",
                                        "        else:\n",
                                        "            result = multi_bands_data[:, index[0]:index[1], index[2]:index[3]] \n",
                                        "    else:\n",
                                        "        result = multi_bands_data[:, index[0]:index[1], index[2]:index[3]]\n",
                                        "    return result.astype(multi_bands_data.dtype)\n",
                                        "\n",
                                        "\n",
                                        "def slice_conbine(slice_all, slice_index):\n",
                                        "    \"\"\"\n",
                                        "    将分块矩阵进行合并\n",
                                        "    :param slice_all: 所有的分块矩阵列表\n",
                                        "    :param slice_index: 分块的四角坐标\n",
                                        "    :return: 合并的矩阵\n",
                                        "    \"\"\"\n",
                                        "    combine_data = np.zeros(shape=(slice_index[-1][1], slice_index[-1][3]))\n",
                                        "    # print(combine_data.shape)\n",
                                        "    for i, slice_element in enumerate(slice_index):\n",
                                        "        combine_data[slice_element[0]:slice_element[1], slice_element[2]:slice_element[3]] = slice_all[i]\n",
                                        "    return combine_data\n",
                                        "\n",
                                        "\n",
                                        "def coordtransf(Xpixel, Ypixel, GeoTransform):\n",
                                        "    \"\"\"\n",
                                        "    像素坐标和地理坐标仿射变换\n",
                                        "    :param Xpixel: 左上角行号\n",
                                        "    :param Ypixel: 左上角列号\n",
                                        "    :param GeoTransform: 原始仿射矩阵\n",
                                        "    :return: 新的仿射矩阵\n",
                                        "    \"\"\"\n",
                                        "    XGeo = GeoTransform[0] + GeoTransform[1] * Xpixel + Ypixel * GeoTransform[2]\n",
                                        "    YGeo = GeoTransform[3] + GeoTransform[4] * Xpixel + Ypixel * GeoTransform[5]\n",
                                        "    slice_geotrans = (XGeo, GeoTransform[1], GeoTransform[2], YGeo, GeoTransform[4], GeoTransform[5])\n",
                                        "    return slice_geotrans\n",
                                        "\n",
                                        "\n",
                                        "def multi_bands_grid_slice(image_path, image_slice_dir, slice_size, edge_fill=False):\n",
                                        "    \"\"\"\n",
                                        "    多波段格网裁剪\n",
                                        "    :param image_path: 原始多波段影像\n",
                                        "    :param image_slice_dir: 裁剪保存文件夹\n",
                                        "    :param slice_size: 裁剪大小\n",
                                        "    :return:\n",
                                        "    \"\"\"\n",
                                        "    image, image_info, image_data = read_multi_bands(image_path)\n",
                                        "\n",
                                        "    # 计算分块的四角行列号\n",
                                        "    slice_index = cal_single_band_slice(image_data[0, :, :], slice_size=slice_size)\n",
                                        "    # 执行裁剪\n",
                                        "    with alive_bar(len(slice_index), force_tty=True) as bar:\n",
                                        "        for i, slice_element in enumerate(slice_index):\n",
                                        "            slice_data = multi_bands_slice(image_data, index=slice_element, slice_size=slice_size,\n",
                                        "                                           edge_fill=edge_fill)  # 裁剪多波段影像\n",
                                        "            slice_geotrans = coordtransf(slice_element[2], slice_element[0], image_info[3])  # 转换仿射坐标\n",
                                        "            image.write_img(image_slice_dir + r'\\multi_grid_slice_' + str(i) + '.tif', slice_data,\n",
                                        "                            img_geotrans=slice_geotrans, img_proj=image_info[4])  # 写入文件\n",
                                        "            bar()\n",
                                        "        print('多波段格网裁剪完成')\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 13,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "ename": "FileNotFoundError",
                                                  "evalue": "[WinError 3] 系统找不到指定的路径。: 'E:\\\\unet_complete_version\\\\raw_material\\\\dataset'",
                                                  "output_type": "error",
                                                  "traceback": [
                                                            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                                                            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                                                            "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124munet_complete_version\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraw_material\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m folder1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder1): os\u001b[38;5;241m.\u001b[39mmkdir(folder1)\n\u001b[0;32m      6\u001b[0m foldertraining \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainning\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(foldertraining): os\u001b[38;5;241m.\u001b[39mmkdir(foldertraining)\n",
                                                            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'E:\\\\unet_complete_version\\\\raw_material\\\\dataset'"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# 创建好带有trainning和label的文件夹\n",
                                        "root = \"raw_material\"\n",
                                        "\n",
                                        "folder1 = os.path.join(root, 'dataset')\n",
                                        "if not os.path.exists(folder1): os.mkdir(folder1)\n",
                                        "foldertraining = os.path.join(folder1, 'trainning')\n",
                                        "if not os.path.exists(foldertraining): os.mkdir(foldertraining)\n",
                                        "\n",
                                        "train_img_folder = os.path.join(foldertraining, 'imgs')\n",
                                        "if not os.path.exists(train_img_folder): os.mkdir(train_img_folder)\n",
                                        "\n",
                                        "train_label_folder = os.path.join(foldertraining, 'labels')\n",
                                        "if not os.path.exists(train_label_folder): os.mkdir(train_label_folder)"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 6,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "多波段影像元信息：[3, 5079, 5079, (2710573.1336033433, 1.9692670323847825, 0.0, 264944.4413223281, 0.0, -1.9692670323847825), 'PROJCS[\"NAD83 / Pennsylvania South (ftUS)\",GEOGCS[\"NAD83\",DATUM[\"North American Datum 1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101004]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",39.3333333333333],PARAMETER[\"central_meridian\",-77.75],PARAMETER[\"standard_parallel_1\",40.9666666666667],PARAMETER[\"standard_parallel_2\",39.9333333333333],PARAMETER[\"false_easting\",1968500],PARAMETER[\"false_northing\",0],UNIT[\"US survey foot\",0.304800609601219,AUTHORITY[\"EPSG\",\"9003\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]']\n",
                                                            "多波段矩阵大小：(3, 5079, 5079)\n",
                                                            "行列数：(5079, 5079)，行分割数量：10，列分割数量：10\n",
                                                            "on 100: 多波段格网裁剪完成                                                               \n",
                                                            "|████████████████████████████████████████| 100/100 [100%] in 2.7s (37.23/s)     \n",
                                                            "单波段影像元信息：[1, 5000, 5000, (2710573.4998999997, 2.0, 0.0, 264943.1693, 0.0, -2.0), 'LOCAL_CS[\"NAD83 / Pennsylvania South (ftUS)\",UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]']\n",
                                                            "单波段矩阵大小：(5000, 5000)\n",
                                                            "行列数：(5000, 5000)，行分割数量：10，列分割数量：10\n",
                                                            "on 100: 单波段格网裁剪完成                                                               \n",
                                                            "|████████████████████████████████████████| 100/100 [100%] in 2.6s (38.11/s)     \n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "# 调用上面的multi_bands_grid_slice和single_band_grid_slice函数进行剪切\n",
                                        "image_path = \"raw_material\\\\naip.tif\"\n",
                                        "image_slice_dir = train_img_folder   \n",
                                        "slice_size = 512\n",
                                        "edge_fill = True\n",
                                        "slice_train = multi_bands_grid_slice(image_path, image_slice_dir, slice_size, edge_fill=edge_fill)\n",
                                        "\n",
                                        "label_path = \"raw_material\\\\landuse.tif\"\n",
                                        "image_slice_dir = train_label_folder\n",
                                        "slice_size = 512\n",
                                        "edge_fill = True\n",
                                        "slice_label= single_band_grid_slice(label_path, image_slice_dir, slice_size, edge_fill=edge_fill)    #一般单波段的影像是用来当label"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 7,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "\n",
                                        "import os \n",
                                        "valid_folder = os.path.join(folder1, 'validation')\n",
                                        "if not os.path.exists(valid_folder): os.mkdir(valid_folder)\n",
                                        "valid_label_folder = os.path.join(valid_folder, 'labels')\n",
                                        "if not os.path.exists(valid_label_folder): os.mkdir(valid_label_folder)\n",
                                        "valid_img_folder = os.path.join(valid_folder, 'imgs')\n",
                                        "if not os.path.exists(valid_img_folder): os.mkdir(valid_img_folder)\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 8,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "# 划分验证集和训练集\n",
                                        "import random\n",
                                        "import shutil\n",
                                        "import os\n",
                                        "from path import Path\n",
                                        "\n",
                                        "\n",
                                        "def split_train_validate(training_img_dir, training_labels_dir, validation_img_dir, validation_labels_dir, split = 10):\n",
                                        "    '''split the training dataset into training and validationg parts, randomly\n",
                                        "    select 10% of the training datast (imgs and labels) into the validation folder\n",
                                        "    '''\n",
                                        "    ## split the train dataset and validation dataset\n",
                                        "    img_sample = random.sample(Path(training_img_dir).files(), len(Path(training_img_dir).files())//split )\n",
                                        "    label_sample = random.sample(Path(training_labels_dir).files(), len(Path(training_labels_dir).files())//split )\n",
                                        "\n",
                                        "    if not os.path.exists(validation_img_dir): os.mkdir(validation_img_dir)\n",
                                        "    if not os.path.exists(validation_labels_dir): os.mkdir(validation_labels_dir)\n",
                                        "\n",
                                        "    for i,j in zip(img_sample,label_sample):\n",
                                        "        shutil.move(os.path.join(training_img_dir, i.name), os.path.join(validation_img_dir, i.name))\n",
                                        "        shutil.move(os.path.join(training_labels_dir, j.name), os.path.join(validation_labels_dir, j.name))\n",
                                        " \n",
                                        "# 创建验证集的文件夹\n",
                                        "valid_folder = os.path.join(folder1, 'validation')\n",
                                        "if not os.path.exists(valid_folder): os.mkdir(valid_folder)\n",
                                        "valid_label_folder = os.path.join(valid_folder, 'labels')\n",
                                        "if not os.path.exists(valid_label_folder): os.mkdir(valid_label_folder)\n",
                                        "valid_img_folder = os.path.join(valid_folder, 'imgs')\n",
                                        "if not os.path.exists(valid_img_folder): os.mkdir(valid_img_folder)\n",
                                        "\n",
                                        "\n",
                                        "split_train_validate(train_img_folder, train_label_folder, valid_img_folder, valid_label_folder)\n"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 16,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "ename": "ModuleNotFoundError",
                                                  "evalue": "No module named 'matplotlib'",
                                                  "output_type": "error",
                                                  "traceback": [
                                                            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                                                            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                                                            "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# # this is used to augment the image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# transform_aug = transforms.Compose([\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#      transforms.RandomHorizontalFlip(p=0.5),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# print('valid_dl is:', len(valid_dl))\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# print('test_dl is:', len(test_dl))\u001b[39;00m\n",
                                                            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import numpy as np\n",
                                        "# import cv2\n",
                                        "from torch.utils.data import Dataset, DataLoader,random_split\n",
                                        "from torchvision import transforms\n",
                                        "import torch\n",
                                        "from pathlib import Path\n",
                                        "import matplotlib.pyplot as plt\n",
                                        "\n",
                                        "\n",
                                        "# # this is used to augment the image\n",
                                        "# transform_aug = transforms.Compose([\n",
                                        "#      transforms.RandomHorizontalFlip(p=0.5),\n",
                                        "#      transforms.RandomRotation(degrees=(-90, 90)),\n",
                                        "#      transforms.RandomVerticalFlip(p=0.5)\n",
                                        "# ])\n",
                                        "\n",
                                        "# class CanopyDataset(Dataset):\n",
                                        "#     def __init__(self, img_dir, msk_dir, pytorch=True, transforms=None):\n",
                                        "#         super().__init__()\n",
                                        "        \n",
                                        "#         img_files = [f for f in img_dir.iterdir() if not f.is_dir()]\n",
                                        "#         mask_files = [f for f in msk_dir.iterdir() if not f.is_dir()]\n",
                                        "\n",
                                        "#         self.files = [self.combine_files(img, mask) for img, mask in zip(img_files, mask_files)]\n",
                                        "#         self.pytorch = pytorch\n",
                                        "#         self.transforms = transforms\n",
                                        "\n",
                                        "#     def combine_files(self, img_file: Path, mask_file: Path):\n",
                                        "#         files = {'image': img_file, 'mask': mask_file}\n",
                                        "#         return files\n",
                                        "    \n",
                                        "#     def __len__(self):\n",
                                        "#         return len(self.files)\n",
                                        "    \n",
                                        "#     def open_as_array(self, idx):\n",
                                        "#         image_path = str(self.files[idx]['image'])\n",
                                        "#         image = cv2.imread(image_path)\n",
                                        "\n",
                                        "        \n",
                                        "#         image = cv2.resize(image, (512, 512))\n",
                                        "#         image = image.transpose((2, 0, 1)) / 255.0\n",
                                        "        \n",
                                        "#         return image\n",
                                        "    \n",
                                        "#     def open_mask(self, idx, add_dims=False):\n",
                                        "#         mask_path = str(self.files[idx]['mask'])\n",
                                        "#         mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
                                        "        \n",
                                        "#         image = cv2.imread(mask_path)\n",
                                        "#         if image is None:\n",
                                        "#             raise ValueError(f\"Image at {mask_path} could not be loaded.\")\n",
                                        "#         mask = cv2.resize(mask, (512, 512))\n",
                                        "#         mask = np.where(mask == 5, 1, 0)\n",
                                        "        \n",
                                        "#         if add_dims:\n",
                                        "#             mask = np.expand_dims(mask, 0)\n",
                                        "        \n",
                                        "#         return mask\n",
                                        "\n",
                                        "#     def __getitem__(self, idx):\n",
                                        "#         image = self.open_as_array(idx)\n",
                                        "#         mask = self.open_mask(idx, add_dims=False)\n",
                                        "\n",
                                        "#         return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.int64)\n",
                                        "    \n",
                                        "#     def __repr__(self):\n",
                                        "#         s = 'Dataset class with {} files'.format(self.__len__ ())\n",
                                        "#         return s\n",
                                        "    \n",
                                        "\n",
                                        "\n",
                                        "# base_path = Path('raw_material\\\\dataset\\\\trainning')\n",
                                        "# data = CanopyDataset(base_path/'imgs', base_path/'labels')\n",
                                        "\n",
                                        "# def check(data):\n",
                                        "#     sample = data.__getitem__(0)\n",
                                        "#     img = sample[0]\n",
                                        "#     label = sample[1]\n",
                                        "#     sample = label.numpy()\n",
                                        "#     img = np.transpose(img, (1, 2, 0))\n",
                                        "#     img = img.numpy()\n",
                                        "#     # 创建一个包含两个子图的图形\n",
                                        "#     fig, axes = plt.subplots(1, 2)\n",
                                        "\n",
                                        "#     # 在第一个子图中显示第一幅图像\n",
                                        "#     axes[0].imshow(label)\n",
                                        "#     axes[0].set_title('label')\n",
                                        "\n",
                                        "#     # 在第二个子图中显示第二幅图像\n",
                                        "#     axes[1].imshow(img)\n",
                                        "#     axes[1].set_title('img')\n",
                                        "\n",
                                        "#     # 调整布局，避免图像重叠\n",
                                        "#     plt.tight_layout()\n",
                                        "\n",
                                        "#     # 显示图形\n",
                                        "#     plt.show()\n",
                                        "\n",
                                        "\n",
                                        "\n",
                                        "# try:\n",
                                        "#     check(data)\n",
                                        "# except ValueError as e:\n",
                                        "#     print(e)\n",
                                        "\n",
                                        "\n",
                                        "# train_ds, valid_ds,test_ds = random_split(data, (70,10,10))\n",
                                        "# train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
                                        "# valid_dl = DataLoader(valid_ds, batch_size=1, shuffle=True)\n",
                                        "# test_dl = DataLoader(test_ds,batch_size=1,shuffle=True)\n",
                                        "# print('train_dl is:', len(train_dl))\n",
                                        "# print(type(train_dl))\n",
                                        "# print('valid_dl is:', len(valid_dl))\n",
                                        "# print('test_dl is:', len(test_dl))"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 10,
                              "metadata": {},
                              "outputs": [],
                              "source": [
                                        "import torch.nn as nn\n",
                                        "import torch\n",
                                        "import numpy as np\n",
                                        "\n",
                                        "\n",
                                        "class UNET(nn.Module):\n",
                                        "    def __init__(self, in_channels, out_channels):\n",
                                        "        super().__init__()\n",
                                        "        \n",
                                        "        #parameters: in_channels, out_channels, kernel_size, padding\n",
                                        "        self.conv1 = self.encoder(in_channels, 64, 3, 1)\n",
                                        "        self.conv2 = self.encoder(64, 128, 3, 1)\n",
                                        "        self.conv3 = self.encoder(128, 256, 3, 1)\n",
                                        "        \n",
                                        "        self.upconv3 = self.decoder(256, 128, 3, 1)\n",
                                        "        self.upconv2 = self.decoder(128*2, 64, 3, 1)\n",
                                        "        self.upconv1 = self.decoder(64*2, out_channels, 3, 1)\n",
                                        "        \n",
                                        "    # will be call when create instance\n",
                                        "    def __call__(self, x): \n",
                                        "        # downsampling part\n",
                                        "        conv1 = self.conv1(x)\n",
                                        "        conv2 = self.conv2(conv1)\n",
                                        "        conv3 = self.conv3(conv2)\n",
                                        "        \n",
                                        "        upconv3 = self.upconv3(conv3)\n",
                                        "        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n",
                                        "        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n",
                                        "        \n",
                                        "        return upconv1\n",
                                        "    \n",
                                        "\n",
                                        "    # ---------------------------------------------------------------------------\n",
                                        "    \n",
                                        "    def encoder(self, in_channels, out_channels, kernel_size, padding):\n",
                                        "        contract = nn.Sequential(\n",
                                        "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding= padding),\n",
                                        "            torch.nn.BatchNorm2d(out_channels),\n",
                                        "            torch.nn.ReLU(),\n",
                                        "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
                                        "            torch.nn.BatchNorm2d(out_channels),\n",
                                        "            torch.nn.ReLU(),\n",
                                        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
                                        "                                 )\n",
                                        "        \n",
                                        "        return contract\n",
                                        "    \n",
                                        "    def decoder(self, in_channels, out_channels, kernel_size, padding):\n",
                                        "        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
                                        "                            torch.nn.BatchNorm2d(out_channels),\n",
                                        "                            torch.nn.ReLU(),\n",
                                        "                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
                                        "                            torch.nn.BatchNorm2d(out_channels),\n",
                                        "                            torch.nn.ReLU(),\n",
                                        "                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
                                        "                            )\n",
                                        "        return expand"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 11,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "Epoch 0/1\n",
                                                            "----------\n",
                                                            "train Loss: 0.7756 Acc: 0.7444175481796265\n",
                                                            "----------\n",
                                                            "Epoch 0/1\n",
                                                            "----------\n",
                                                            "valid Loss: 0.4949 Acc: 0.8097503781318665\n",
                                                            "----------\n",
                                                            "Epoch 1/1\n",
                                                            "----------\n",
                                                            "train Loss: 0.5352 Acc: 0.7827494144439697\n",
                                                            "----------\n",
                                                            "Epoch 1/1\n",
                                                            "----------\n",
                                                            "valid Loss: 0.4944 Acc: 0.8097503781318665\n",
                                                            "----------\n",
                                                            "Training complete in 0m 24s\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "import time\n",
                                        "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs):\n",
                                        "    start = time.time()\n",
                                        "    model.cuda()\n",
                                        "    \n",
                                        "    train_loss, valid_loss = [], []\n",
                                        "    \n",
                                        "    best_acc = 0.0\n",
                                        "    \n",
                                        "    for epoch in range(epochs):\n",
                                        "        \n",
                                        "        # print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
                                        "        # print('-' * 10)\n",
                                        "        \n",
                                        "        for phase in ['train', 'valid']:\n",
                                        "            if phase == 'train':\n",
                                        "                model.train(True)  # Set trainind mode = true\n",
                                        "                dataloader = train_dl\n",
                                        "            else:\n",
                                        "                model.train(False)  # Set model to evaluate mode\n",
                                        "                dataloader = valid_dl\n",
                                        "\n",
                                        "\n",
                                        "            running_loss = 0.0\n",
                                        "            running_acc = 0.0\n",
                                        "\n",
                                        "            step = 0\n",
                                        "\n",
                                        "            # iterate over data\n",
                                        "            for x, y in dataloader:\n",
                                        "                x = x.cuda()\n",
                                        "                y = y.cuda()\n",
                                        "                step += 1\n",
                                        "\n",
                                        "                # forward pass\n",
                                        "                if phase == 'train':\n",
                                        "                    # zero the gradients\n",
                                        "                    optimizer.zero_grad()\n",
                                        "                    outputs = model(x)\n",
                                        "                    loss = loss_fn(outputs, y)\n",
                                        "                    # the backward pass frees the graph memory, so there is no \n",
                                        "                    # need for torch.no_grad in this training pass\n",
                                        "                    loss.backward()\n",
                                        "                    optimizer.step()\n",
                                        "\n",
                                        "\n",
                                        "                else:\n",
                                        "                    with torch.no_grad():\n",
                                        "                        outputs = model(x)\n",
                                        "                        loss = loss_fn(outputs, y.long())\n",
                                        "                        \n",
                                        "                # stats - whatever is the phase\n",
                                        "                acc = acc_fn(outputs, y)\n",
                                        "                \n",
                                        "                running_acc  += acc*dataloader.batch_size\n",
                                        "                running_loss += loss*dataloader.batch_size \n",
                                        "                \n",
                                        "\n",
                                        "                if step % 100 == 0:\n",
                                        "                    # clear_output(wait=True)\n",
                                        "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
                                        "                    # print(torch.cuda.memory_summary())\n",
                                        "\n",
                                        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
                                        "            epoch_acc = running_acc / len(dataloader.dataset)\n",
                                        "            \n",
                                        "            # clear_output(wait=True)\n",
                                        "            print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
                                        "            print('-' * 10)\n",
                                        "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
                                        "            print('-' * 10)\n",
                                        "            \n",
                                        "\n",
                                        "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
                                        "    \n",
                                        "\n",
                                        "    time_elapsed = time.time() - start\n",
                                        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
                                        "    \n",
                                        "    return train_loss, valid_loss    \n",
                                        "\n",
                                        "def batch_to_img(xb, idx):\n",
                                        "    img = np.array(xb[idx,0:3])\n",
                                        "    return img.transpose((1,2,0))\n",
                                        "\n",
                                        "def predb_to_mask(predb, idx):\n",
                                        "    p = torch.functional.F.softmax(predb[idx], 0)\n",
                                        "    return p.argmax(0).cpu()\n",
                                        "\n",
                                        "def acc_metric(predb, yb):\n",
                                        "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()\n",
                                        "\n",
                                        "\n",
                                        "unet = UNET(3,8)\n",
                                        "\n",
                                        "loss_fn = nn.CrossEntropyLoss()\n",
                                        "opt = torch.optim.Adam(unet.parameters(), lr=0.01)\n",
                                        "train_loss, valid_loss = train(unet, train_dl, valid_dl, loss_fn, opt, acc_metric, epochs=2)\n",
                                        "\n",
                                        "tem = torch.save(unet.state_dict(), 'unet_build_model100epc_aug.pth')"
                              ]
                    },
                    {
                              "cell_type": "code",
                              "execution_count": 12,
                              "metadata": {},
                              "outputs": [
                                        {
                                                  "name": "stdout",
                                                  "output_type": "stream",
                                                  "text": [
                                                            "10\n",
                                                            "Average Accuracy: 0.7719429135322571\n"
                                                  ]
                                        }
                              ],
                              "source": [
                                        "model = UNET(3,8)\n",
                                        "\n",
                                        "model_path = r'unet_build_model100epc_aug.pth'\n",
                                        "model.load_state_dict(torch.load(model_path))\n",
                                        "\n",
                                        "model.eval()\n",
                                        "print(len(test_dl))\n",
                                        "\n",
                                        "\n",
                                        "total_acc = 0  \n",
                                        "num_batches = 0  \n",
                                        "with torch.no_grad():\n",
                                        "    for xb,yb in test_dl:\n",
                                        "        output = model(xb).to('cuda:0') \n",
                                        "        acc = acc_metric(output,yb)\n",
                                        "        total_acc += acc\n",
                                        "        num_batches+=1\n",
                                        "\n",
                                        "average_acc = total_acc / num_batches  \n",
                                        "print(f\"Average Accuracy: {average_acc}\")\n",
                                        "        \n",
                                        "# print(output.shape)\n",
                                        "# ## batch size\n",
                                        "# bs = 1\n",
                                        "# fig, ax = plt.subplots(bs, 3, figsize=(15, bs*5))\n",
                                        "# for i in range(bs):\n",
                                        "#     ax[i,0].imshow(batch_to_img(xb,i))\n",
                                        "#     ax[i,1].imshow(yb[i])\n",
                                        "#     ax[i,2].imshow(predb_to_mask(output, i))\n",
                                        "    \n"
                              ]
                    }
          ],
          "metadata": {
                    "kernelspec": {
                              "display_name": "pytorch",
                              "language": "python",
                              "name": "python3"
                    },
                    "language_info": {
                              "codemirror_mode": {
                                        "name": "ipython",
                                        "version": 3
                              },
                              "file_extension": ".py",
                              "mimetype": "text/x-python",
                              "name": "python",
                              "nbconvert_exporter": "python",
                              "pygments_lexer": "ipython3",
                              "version": "3.9.19"
                    }
          },
          "nbformat": 4,
          "nbformat_minor": 2
}
