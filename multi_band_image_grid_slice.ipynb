{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c4b51d-9253-48fb-a327-6228f913ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import os\n",
    "# os.environ['PROJ_LIB'] = r'C:\\Users\\Lenovo\\.conda\\envs\\zph\\Library\\share\\proj'\n",
    "# os.environ['GDAL_DATA'] = r'C:\\Users\\Lenovo\\.conda\\envs\\zph\\Library\\share'\n",
    "# gdal.PushErrorHandler(\"CPLQuietErrorHandler\")\n",
    "\n",
    "\n",
    "class ImageProcess:\n",
    "    def __init__(self, filepath: str):\n",
    "        self.filepath = filepath\n",
    "        self.dataset = gdal.Open(self.filepath, gdal.GA_ReadOnly)\n",
    "        self.info = []\n",
    "        self.img_data = None\n",
    "        self.data_8bit = None\n",
    "\n",
    "    def read_img_info(self):\n",
    "        # 获取波段、宽、高\n",
    "        img_bands = self.dataset.RasterCount\n",
    "        img_width = self.dataset.RasterXSize\n",
    "        img_height = self.dataset.RasterYSize\n",
    "        # 获取仿射矩阵、投影\n",
    "        img_geotrans = self.dataset.GetGeoTransform()\n",
    "        img_proj = self.dataset.GetProjection()\n",
    "        self.info = [img_bands, img_width, img_height, img_geotrans, img_proj]\n",
    "        return self.info\n",
    "\n",
    "    def read_img_data(self):\n",
    "        self.img_data = self.dataset.ReadAsArray(0, 0, self.info[1], self.info[2])\n",
    "        return self.img_data\n",
    "\n",
    "    # 影像写入文件\n",
    "    @staticmethod\n",
    "    def write_img(filename: str, img_data: np.array, **kwargs):\n",
    "        # 判断栅格数据的数据类型\n",
    "        if 'int8' in img_data.dtype.name:\n",
    "            datatype = gdal.GDT_Byte\n",
    "        elif 'int16' in img_data.dtype.name:\n",
    "            datatype = gdal.GDT_UInt16\n",
    "        else:\n",
    "            datatype = gdal.GDT_Float32\n",
    "        # 判读数组维数\n",
    "        if len(img_data.shape) >= 3:\n",
    "            img_bands, img_height, img_width = img_data.shape\n",
    "        else:\n",
    "            img_bands, (img_height, img_width) = 1, img_data.shape\n",
    "        # 创建文件\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        outdataset = driver.Create(filename, img_width, img_height, img_bands, datatype)\n",
    "        # 写入仿射变换参数\n",
    "        if 'img_geotrans' in kwargs:\n",
    "            outdataset.SetGeoTransform(kwargs['img_geotrans'])\n",
    "        # 写入投影\n",
    "        if 'img_proj' in kwargs:\n",
    "            outdataset.SetProjection(kwargs['img_proj'])\n",
    "        # 写入文件\n",
    "        if img_bands == 1:\n",
    "            outdataset.GetRasterBand(1).WriteArray(img_data)  # 写入数组数据\n",
    "        else:\n",
    "            for i in range(img_bands):\n",
    "                outdataset.GetRasterBand(i + 1).WriteArray(img_data[i])\n",
    "\n",
    "        del outdataset\n",
    "\n",
    "\n",
    "def read_multi_bands(image_path):\n",
    "    \"\"\"\n",
    "    读取多波段文件\n",
    "    :param image_path: 多波段文件路径\n",
    "    :return: 影像对象，影像元信息，影像矩阵\n",
    "    \"\"\"\n",
    "    # 影像读取\n",
    "    image = ImageProcess(filepath=image_path)\n",
    "    # 读取影像元信息\n",
    "    image_info = image.read_img_info()\n",
    "    print(f\"多波段影像元信息：{image_info}\")\n",
    "    # 读取影像矩阵\n",
    "    image_data = image.read_img_data()\n",
    "    print(f\"多波段矩阵大小：{image_data.shape}\")\n",
    "    return image, image_info, image_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a8b0d8-3d94-4226-9405-e31e5cb1b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "\n",
    "\n",
    "def cal_single_band_slice(single_band_data, slice_size=512):\n",
    "    \"\"\"\n",
    "    计算单波段的格网裁剪四角点\n",
    "    :param single_band_data:单波段原始数据\n",
    "    :param slice_size: 裁剪大小\n",
    "    :return: 嵌套列表，每一个块的四角行列号\n",
    "    \"\"\"\n",
    "    single_band_size = single_band_data.shape\n",
    "    row_num = math.ceil(single_band_size[0] / slice_size)  # 向上取整\n",
    "    col_num = math.ceil(single_band_size[1] / slice_size)  # 向上取整\n",
    "    print(f\"行列数：{single_band_size}，行分割数量：{row_num}，列分割数量：{col_num}\")\n",
    "    slice_index = []\n",
    "    for i in range(row_num):\n",
    "        for j in range(col_num):\n",
    "            row_min = i * slice_size\n",
    "            row_max = (i + 1) * slice_size\n",
    "            if (i + 1) * slice_size > single_band_size[0]:\n",
    "                row_max = single_band_size[0]\n",
    "            col_min = j * slice_size\n",
    "            col_max = (j + 1) * slice_size\n",
    "            if (j + 1) * slice_size > single_band_size[1]:\n",
    "                col_max = single_band_size[1]\n",
    "            slice_index.append([row_min, row_max, col_min, col_max])\n",
    "    return slice_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multi_bands_slice(multi_bands_data, index=[0, 512, 0, 512], slice_size=512, edge_fill=False):\n",
    "    \"\"\"\n",
    "    依据四角坐标，切分多波段影像\n",
    "    :param multi_bands_data: 原始多波段矩阵\n",
    "    :param index: 四角坐标\n",
    "    :param slice_size: 分块大小\n",
    "    :param edge_fill: 是否进行边缘填充\n",
    "    :return: 切分好的多波段矩阵\n",
    "    \"\"\"\n",
    "    if edge_fill==True:\n",
    "        if (index[1] - index[0] != slice_size) or (index[3] - index[2] != slice_size):\n",
    "            result = np.empty(shape=(multi_bands_data.shape[0], slice_size, slice_size))\n",
    "            new_row_min = index[0] % slice_size    # 0\n",
    "            new_row_max = new_row_min + (index[1] - index[0])  \n",
    "            new_col_min = index[2] % slice_size    # 0\n",
    "            new_col_max = new_col_min + (index[3] - index[2])\n",
    "            result[:, new_row_min:new_row_max, new_col_min:new_col_max] = multi_bands_data[:, index[0]:index[1],\n",
    "                                                                          index[2]:index[3]]\n",
    "        else:\n",
    "            result = multi_bands_data[:, index[0]:index[1], index[2]:index[3]] \n",
    "    else:\n",
    "        result = multi_bands_data[:, index[0]:index[1], index[2]:index[3]]\n",
    "    return result.astype(multi_bands_data.dtype)\n",
    "\n",
    "\n",
    "def slice_conbine(slice_all, slice_index):\n",
    "    \"\"\"\n",
    "    将分块矩阵进行合并\n",
    "    :param slice_all: 所有的分块矩阵列表\n",
    "    :param slice_index: 分块的四角坐标\n",
    "    :return: 合并的矩阵\n",
    "    \"\"\"\n",
    "    combine_data = np.zeros(shape=(slice_index[-1][1], slice_index[-1][3]))\n",
    "    # print(combine_data.shape)\n",
    "    for i, slice_element in enumerate(slice_index):\n",
    "        combine_data[slice_element[0]:slice_element[1], slice_element[2]:slice_element[3]] = slice_all[i]\n",
    "    return combine_data\n",
    "\n",
    "\n",
    "def coordtransf(Xpixel, Ypixel, GeoTransform):\n",
    "    \"\"\"\n",
    "    像素坐标和地理坐标仿射变换\n",
    "    :param Xpixel: 左上角行号\n",
    "    :param Ypixel: 左上角列号\n",
    "    :param GeoTransform: 原始仿射矩阵\n",
    "    :return: 新的仿射矩阵\n",
    "    \"\"\"\n",
    "    XGeo = GeoTransform[0] + GeoTransform[1] * Xpixel + Ypixel * GeoTransform[2]\n",
    "    YGeo = GeoTransform[3] + GeoTransform[4] * Xpixel + Ypixel * GeoTransform[5]\n",
    "    slice_geotrans = (XGeo, GeoTransform[1], GeoTransform[2], YGeo, GeoTransform[4], GeoTransform[5])\n",
    "    return slice_geotrans\n",
    "\n",
    "\n",
    "def multi_bands_grid_slice(image_path, image_slice_dir, slice_size, edge_fill=False):\n",
    "    \"\"\"\n",
    "    多波段格网裁剪\n",
    "    :param image_path: 原始多波段影像\n",
    "    :param image_slice_dir: 裁剪保存文件夹\n",
    "    :param slice_size: 裁剪大小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image, image_info, image_data = read_multi_bands(image_path)\n",
    "\n",
    "    # 计算分块的四角行列号\n",
    "    slice_index = cal_single_band_slice(image_data[0, :, :], slice_size=slice_size)\n",
    "    # 执行裁剪\n",
    "    with alive_bar(len(slice_index), force_tty=True) as bar:\n",
    "        for i, slice_element in enumerate(slice_index):\n",
    "            slice_data = multi_bands_slice(image_data, index=slice_element, slice_size=slice_size,\n",
    "                                           edge_fill=edge_fill)  # 裁剪多波段影像\n",
    "            slice_geotrans = coordtransf(slice_element[2], slice_element[0], image_info[3])  # 转换仿射坐标\n",
    "            image.write_img(image_slice_dir + r'\\multi_grid_slice_' + str(i) + '.tif', slice_data,\n",
    "                            img_geotrans=slice_geotrans, img_proj=image_info[4])  # 写入文件\n",
    "            bar()\n",
    "        print('多波段格网裁剪完成')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e5dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多波段影像元信息：[3, 5079, 5079, (2710573.1336033433, 1.9692670323847825, 0.0, 264944.4413223281, 0.0, -1.9692670323847825), 'PROJCS[\"NAD83 / Pennsylvania South (ftUS)\",GEOGCS[\"NAD83\",DATUM[\"North American Datum 1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101004]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",39.3333333333333],PARAMETER[\"central_meridian\",-77.75],PARAMETER[\"standard_parallel_1\",40.9666666666667],PARAMETER[\"standard_parallel_2\",39.9333333333333],PARAMETER[\"false_easting\",1968500],PARAMETER[\"false_northing\",0],UNIT[\"US survey foot\",0.304800609601219,AUTHORITY[\"EPSG\",\"9003\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]']\n",
      "多波段矩阵大小：(3, 5079, 5079)\n",
      "行列数：(5079, 5079)，行分割数量：10，列分割数量：10\n",
      "on 100: 多波段格网裁剪完成                                                               \n",
      "|████████████████████████████████████████| 100/100 [100%] in 1.9s (52.33/s)     \n"
     ]
    }
   ],
   "source": [
    "image_path = \"E:\\\\unet_complete_version\\\\raw_material\\\\data\\\\naip.tif\"\n",
    "image_slice_dir = \"dataset_result\\imagry\"\n",
    "slice_size = 512\n",
    "edge_fill = True\n",
    "slice = multi_bands_grid_slice(image_path, image_slice_dir, slice_size, edge_fill=edge_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# this is used to augment the image\n",
    "transform_aug = transforms.Compose([\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomRotation(degrees=(-90, 90)),\n",
    "     transforms.RandomVerticalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, msk_dir, pytorch=True, transforms=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.files = [self.combine_files(f, img_dir, msk_dir) for f in img_dir.iterdir() if not f.is_dir()]\n",
    "        self.pytorch = pytorch\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def combine_files(self, r_file: Path, img_dir, msk_dir):\n",
    "        files = {'image': r_file, \n",
    "                 'mask': msk_dir/r_file.name.replace('naip_tiles', 'lu_masks')}\n",
    "        return files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def open_as_array(self, idx, augment=False):\n",
    "        image_path = str(self.files[idx]['image'])\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if augment:\n",
    "            # Apply augmentation to the image\n",
    "            # You can add your image augmentation logic here\n",
    "            pass\n",
    "        \n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        image = image.transpose((2, 0, 1)) / 255.0\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def open_mask(self, idx, add_dims=False, augment=False):\n",
    "        mask_path = str(self.files[idx]['mask'])\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if augment:\n",
    "            # Apply augmentation to the mask\n",
    "            # You can add your mask augmentation logic here\n",
    "            pass\n",
    "\n",
    "        mask = cv2.resize(mask, (512, 512))\n",
    "        mask = np.where(mask == 5, 1, 0)\n",
    "        \n",
    "        if add_dims:\n",
    "            mask = np.expand_dims(mask, 0)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.open_as_array(idx, augment=True)\n",
    "        mask = self.open_mask(idx, add_dims=False, augment=True)\n",
    "        \n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.int64)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'Dataset class with {} files'.format(self.__len())\n",
    "        return s\n",
    "\n",
    "base_path = Path('raw_material\\\\overall data\\\\dataset\\\\trainning')\n",
    "data = CustomDataset(base_path/'imgs', base_path/'labels')\n",
    "print(len(data))\n",
    "\n",
    "train_ds, valid_ds = torch.utils.data.random_split(data, (300, 20))\n",
    "train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "print('train_dl is:', len(train_dl))\n",
    "print('valid_dl is:', len(valid_dl))\n",
    "for batch in valid_dl:\n",
    "    if batch is None:\n",
    "        print(\"Data batch is empty\")\n",
    "    else:\n",
    "        print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
